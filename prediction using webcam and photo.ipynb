{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For live streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def detect_faces(image):\n",
    "    \"\"\"\n",
    "        Using dlib library to extract faces from images, as the model was trained on faces.\n",
    "        It would be better to use `dlib.cnn_face_detection_model_v1` but slower (http://dlib.net/cnn_face_detector.py.html)    \n",
    "    \"\"\"\n",
    "    face_detector=dlib.get_frontal_face_detector()\n",
    "    detected_faces=face_detector(image,1)\n",
    "    face_frames=[(x.left(),x.top(),x.right(),x.bottom()) for x in detected_faces]\n",
    "    \n",
    "    #using cnn face detector\n",
    "    #cnn_face_detector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n",
    "    # get `mmod_human_face_detector.dat` at http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
    "    #detected_faces=cnn_face_detector(img,1)\n",
    "    #face_frames=[(x.rect.left(),x.rect.top(),x.rect.right(),x.rect.bottom()) for x in detected_faces]\n",
    "    \n",
    "    return face_frames\n",
    "\n",
    "def predict_on_image(model, in_image_path):\n",
    "    \"\"\"\n",
    "        Makes prediction for imge(at `in_image_path`) and returns one of {\"open\", \"close\", \"noface\"}\n",
    "        `model_path` - path to Keras model data (containing model layer data, model config data and weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    def label_img(img, label, loc=(3,50)): #annotates the image with the predicted label (close/open)\n",
    "        return cv2.putText(img, label, loc, cv2.FONT_HERSHEY_SIMPLEX, 3.4, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    classes={1:\"open\",0:\"close\"}\n",
    "    image=io.imread(in_image_path)\n",
    "    face_rect=detect_faces(image)\n",
    "    if len(face_rect)>0:\n",
    "        image=np.array(Image.fromarray(image).crop(face_rect[0]))\n",
    "    else:\n",
    "        return \"noface\"\n",
    "    # preprocess image - resize and remove mean from RGB channels\n",
    "    processed_image=np.stack([cv2.resize(preprocess_input(img.astype(np.float32)),(224,224)) for img in [image]], axis=0)\n",
    "    pred=model.predict(processed_image)    \n",
    "    labels=[classes[p] for p in np.argmax(pred, axis=1)] #close/open label for image\n",
    "    showStatistics(labels[0])\n",
    "    return labels[0]\n",
    "\n",
    "\n",
    "def showStatistics(label):\n",
    "\n",
    "    textImage = np.zeros((300,512,3), np.uint8)\n",
    "    className = \"\"\n",
    "    cv2.putText(textImage,\"Pedicted Class : \" + label, \n",
    "    (30, 30), \n",
    "    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "    1,\n",
    "    (255, 255, 255),\n",
    "    2)\n",
    "    cv2.imshow(\"Statistics\", textImage)\n",
    "\n",
    "def main():\n",
    "    model_path=\"best.h5\"\n",
    "    model=keras.models.load_model(model_path)\n",
    "\n",
    "    # get the reference to the webcam\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    start_recording = False\n",
    "    while(1):\n",
    "        ret, img = camera.read()\n",
    "    \n",
    "        if start_recording:\n",
    "            # display the frame with segmented hand\n",
    "            cv2.imwrite('Temp_Eye_Grey.jpg',img)\n",
    "            predict_on_image(model, 'Temp_Eye_Grey.jpg')\n",
    "            \n",
    "        cv2.imshow('img',img)\n",
    "        # observe the keypress by the user\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if user press q then it will stop looping\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "        #if user press s then it starts showing the o/p\n",
    "        if keypress == ord(\"s\"):\n",
    "            start_recording = True\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_on_image(model_path, in_image_path):\n",
    "    \"\"\"\n",
    "        Makes prediction for imge(at `in_image_path`) and returns one of {\"open\", \"close\", \"noface\"}\n",
    "        `model_path` - path to Keras model data (containing model layer data, model config data and weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    def label_img(img, label, loc=(3,50)): #annotates the image with the predicted label (close/open)\n",
    "        return cv2.putText(img, label, loc, cv2.FONT_HERSHEY_SIMPLEX, 3.4, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    classes={1:\"open\",0:\"close\"}\n",
    "    model=keras.models.load_model(model_path)\n",
    "    image=io.imread(in_image_path)\n",
    "    face_rect=detect_faces(image)\n",
    "    if len(face_rect)>0:\n",
    "        image=np.array(Image.fromarray(image).crop(face_rect[0]))\n",
    "    else:\n",
    "        return \"noface\"\n",
    "    # preprocess image - resize and remove mean from RGB channels\n",
    "    processed_image=np.stack([cv2.resize(preprocess_input(img.astype(np.float32)),(224,224)) for img in [image]], axis=0)\n",
    "    pred=model.predict(processed_image)\n",
    "    print(pred)\n",
    "    labels=[classes[p] for p in np.argmax(pred, axis=1)] #close/open label for image\n",
    "    return labels[0]\n",
    "\n",
    "model_path=\"best.h5\"\n",
    "in_image_path=\"closed.jpg\"#pass the name of your image or the path\n",
    "predict_on_image(model_path, in_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
